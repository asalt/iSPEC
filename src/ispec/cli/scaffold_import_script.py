from __future__ import annotations

import os
import re
import textwrap
from dataclasses import dataclass
from pathlib import Path
from typing import Sequence


DEFAULT_INCLUDE_EXTS = "png,pdf,tsv,tab,gct"
DEFAULT_EXCLUDE_EXTS = "sqlite,rds"


def _slugify(value: str) -> str:
    text = (value or "").strip().lower()
    text = re.sub(r"[^a-z0-9]+", "_", text)
    return text.strip("_")


def _parse_ext_list(values: Sequence[str] | None) -> list[str]:
    if not values:
        return []
    out: list[str] = []
    for item in values:
        for part in str(item).split(","):
            ext = part.strip().lower().lstrip(".")
            if ext:
                out.append(ext)
    return out


def _guess_data_gct_dir(results_dir: Path) -> Path | None:
    """Try to find an export/data_gct directory near the results folder."""

    candidates = [
        results_dir / "export" / "data_gct",
        results_dir.parent / "export" / "data_gct",
        results_dir.parent.parent / "export" / "data_gct",
    ]
    for candidate in candidates:
        if candidate.is_dir():
            return candidate
    return None


def _bash_escape(value: str) -> str:
    return value.replace("\\", "\\\\").replace('"', '\\"')


@dataclass(frozen=True)
class ScaffoldImportScriptResult:
    content: str
    out_path: Path | None
    script_name: str
    gct_dir: Path | None


def scaffold_import_results_script(
    *,
    project_id: int,
    results_dir: str,
    out: str | None,
    mspc_id: str | None = None,
    tag: str | None = None,
    script_name: str | None = None,
    prefix: str | None = None,
    include_ext: Sequence[str] | None = None,
    exclude_ext: Sequence[str] | None = None,
    with_gct_export: bool = False,
    gct_dir: str | None = None,
    prefix_gct: str | None = None,
    force: bool = False,
) -> ScaffoldImportScriptResult:
    results_path = Path(str(results_dir)).expanduser().resolve(strict=False)
    default_prefix = (prefix or results_path.name).strip() or results_path.name

    include_exts = ",".join(_parse_ext_list(include_ext)) if include_ext else DEFAULT_INCLUDE_EXTS
    exclude_exts = ",".join(_parse_ext_list(exclude_ext)) if exclude_ext else DEFAULT_EXCLUDE_EXTS

    resolved_gct_dir: Path | None = None
    if with_gct_export:
        if gct_dir:
            resolved_gct_dir = Path(str(gct_dir)).expanduser().resolve(strict=False)
        else:
            resolved_gct_dir = _guess_data_gct_dir(results_path)

    resolved_prefix_gct = (prefix_gct or f"{default_prefix}__export__data_gct").strip()

    suggested_name = (
        script_name
        or "_".join(
            part
            for part in [
                f"import_project{int(project_id)}",
                _slugify(mspc_id or ""),
                _slugify(tag or ""),
            ]
            if part
        )
        + ".sh"
    )
    suggested_name = suggested_name.replace("__", "_")

    out_path: Path | None = None
    if out:
        out_candidate = Path(str(out)).expanduser()
        out_path = out_candidate / suggested_name if out_candidate.is_dir() else out_candidate
        out_path = out_path.resolve(strict=False)
        if out_path.exists() and not force:
            raise FileExistsError(f"Refusing to overwrite existing file: {out_path} (use --force)")

    results_default = _bash_escape(str(results_path))
    gct_default = _bash_escape(str(resolved_gct_dir)) if resolved_gct_dir else ""

    header = f"""\
#!/usr/bin/env bash
set -euo pipefail

# Generated by: ispec db scaffold-import-script
# Project ID: {int(project_id)}
# Results dir: {results_default}
#
# This script is intentionally "just paths + CLI calls" so we can keep a record
# of what was imported for a given project while the Python import routines
# evolve inside the `ispec` package.
#
# Notes:
# - Only "user-facing" artifacts are attached to project files by default:
#   PNG/PDF/TSV/TAB/GCT, excluding cache files like SQLITE/RDS.
# - Volcano-style TSVs (with a GeneID column) can also be imported into the omics DB.
"""

    gct_block = ""
    usage_gct = ""
    parse_gct = ""
    extra_echo_gct = ""
    if with_gct_export:
        usage_gct = "  --prefix-gct <name>      Prefix for GCT export attachments (default: ${PREFIX_GCT})\n"
        parse_gct = """\
    --prefix-gct)
      PREFIX_GCT="${2:-}"
      shift 2
      ;;
"""
        extra_echo_gct = """\
echo "GCT dir:       ${RESULTS_GCT_DIR}"
echo "GCT prefix:    ${PREFIX_GCT}"
"""
        gct_block = f"""
RESULTS_GCT_DIR="${{RESULTS_GCT_DIR:-{gct_default}}}"
PREFIX_GCT="${{PREFIX_GCT:-{_bash_escape(resolved_prefix_gct)}}}"
INCLUDE_GCT_EXTS="${{INCLUDE_GCT_EXTS:-gct}}"
"""

    body = f"""
PROJECT_ID="${{PROJECT_ID:-{int(project_id)}}}"

RESULTS_DIR="${{RESULTS_DIR:-{results_default}}}"
PREFIX="${{PREFIX:-{_bash_escape(default_prefix)}}}"

INCLUDE_EXTS="${{INCLUDE_EXTS:-{_bash_escape(include_exts)}}}"
EXCLUDE_EXTS="${{EXCLUDE_EXTS:-{_bash_escape(exclude_exts)}}}"

DATABASE=""
OMICS_DATABASE=""
DRY_RUN=0
FORCE=0
ADDED_BY="${{ADDED_BY:-}}"
IMPORT_VOLCANO=1
{gct_block}
usage() {{
  cat <<EOF
Usage: $(basename "$0") --database <db_path> [options]

Options:
  --database <path>        SQLite DB path/URI to write to (required)
  --omics-database <path>  SQLite omics DB path/URI (defaults to ISPEC_OMICS_DB_PATH/derived)
  --prefix <name>          Prefix for stored filenames in project_file (default: ${{PREFIX}})
{usage_gct}  --added-by <username>    Record in prjfile_AddedBy for attachments
  --no-volcano             Do not import volcano TSVs into the omics DB
  --dry-run                Do not write; report what would be imported
  --force                  Overwrite attachments that share the same stored name

Environment overrides:
  PROJECT_ID, RESULTS_DIR, PREFIX,
  INCLUDE_EXTS, EXCLUDE_EXTS,
  ADDED_BY
EOF
}}

while [[ $# -gt 0 ]]; do
  case "$1" in
    --database)
      DATABASE="${{2:-}}"
      shift 2
      ;;
    --omics-database)
      OMICS_DATABASE="${{2:-}}"
      shift 2
      ;;
    --prefix)
      PREFIX="${{2:-}}"
      shift 2
      ;;
{parse_gct}    --added-by)
      ADDED_BY="${{2:-}}"
      shift 2
      ;;
    --no-volcano)
      IMPORT_VOLCANO=0
      shift
      ;;
    --dry-run)
      DRY_RUN=1
      shift
      ;;
    --force)
      FORCE=1
      shift
      ;;
    -h|--help)
      usage
      exit 0
      ;;
    *)
      echo "Unknown arg: $1" >&2
      usage >&2
      exit 2
      ;;
  esac
done

if [[ -z "$DATABASE" ]]; then
  echo "--database is required" >&2
  usage >&2
  exit 2
fi

SCRIPT_DIR="$(cd "$(dirname "${{BASH_SOURCE[0]}}")" && pwd)"
ISPEC_ROOT="$(cd "${{SCRIPT_DIR}}/.." && pwd)"
ISPEC_FULL_ROOT="$(cd "${{ISPEC_ROOT}}/.." && pwd)"

ISPEC_BIN="${{ISPEC_BIN:-${{ISPEC_ROOT}}/.venv/bin/ispec}}"
if [[ ! -x "$ISPEC_BIN" ]]; then
  if command -v ispec >/dev/null 2>&1; then
    ISPEC_BIN="ispec"
  else
    echo "Unable to find iSPEC CLI. Activate iSPEC/.venv or set ISPEC_BIN=/path/to/ispec." >&2
    exit 1
  fi
fi

ISPEC_ENV_FILE="${{ISPEC_ENV_FILE:-}}"
if [[ -z "$ISPEC_ENV_FILE" ]]; then
  DEFAULT_ENV_FILE="${{ISPEC_FULL_ROOT}}/.env.local"
  if [[ -f "$DEFAULT_ENV_FILE" ]]; then
    ISPEC_ENV_FILE="$DEFAULT_ENV_FILE"
  fi
fi

ENV_ARGS=()
if [[ -n "$ISPEC_ENV_FILE" ]]; then
  if [[ ! -f "$ISPEC_ENV_FILE" ]]; then
    echo "Env file not found: ${{ISPEC_ENV_FILE}}" >&2
    exit 1
  fi
  ENV_ARGS+=(--env-file "$ISPEC_ENV_FILE")
fi

COMMON_ARGS=(
  --database "$DATABASE"
  --include-ext "$INCLUDE_EXTS"
  --exclude-ext "$EXCLUDE_EXTS"
)
if [[ -n "$OMICS_DATABASE" ]]; then
  COMMON_ARGS+=(--omics-database "$OMICS_DATABASE")
fi
if [[ -n "$ADDED_BY" ]]; then
  COMMON_ARGS+=(--added-by "$ADDED_BY")
fi
if [[ "$DRY_RUN" -eq 1 ]]; then
  COMMON_ARGS+=(--dry-run)
fi
if [[ "$FORCE" -eq 1 ]]; then
  COMMON_ARGS+=(--force)
fi
if [[ "$IMPORT_VOLCANO" -eq 0 ]]; then
  COMMON_ARGS+=(--no-import-volcano)
fi

run_cmd() {{
  echo "+ $*"
  "$@"
}}

echo "Project ID:    ${{PROJECT_ID}}"
echo "Database:      ${{DATABASE}}"
if [[ -n "$ISPEC_ENV_FILE" ]]; then
  echo "Env file:      ${{ISPEC_ENV_FILE}}"
fi
if [[ -n "$OMICS_DATABASE" ]]; then
  echo "Omics DB:      ${{OMICS_DATABASE}}"
fi
echo "Results dir:   ${{RESULTS_DIR}}"
echo "Prefix:        ${{PREFIX}}"
{extra_echo_gct}echo "Include exts:  ${{INCLUDE_EXTS}}"
echo "Exclude exts:  ${{EXCLUDE_EXTS}}"
if [[ -n "$ADDED_BY" ]]; then
  echo "Added by:      ${{ADDED_BY}}"
fi
echo "Import volcano: ${{IMPORT_VOLCANO}}"
echo "Dry run:       ${{DRY_RUN}}"
echo "Force:         ${{FORCE}}"
echo

run_cmd "$ISPEC_BIN" "${{ENV_ARGS[@]}}" db import-results \\
  --project-id "$PROJECT_ID" \\
  --results-dir "$RESULTS_DIR" \\
  --prefix "$PREFIX" \\
  "${{COMMON_ARGS[@]}}"
"""

    if with_gct_export:
        body += """

if [[ -n "$RESULTS_GCT_DIR" ]] && [[ -d "$RESULTS_GCT_DIR" ]]; then
  echo
  echo "== Import: GCT exports =="

  GCT_ARGS=(
    --database "$DATABASE"
    --include-ext "$INCLUDE_GCT_EXTS"
    --exclude-ext "$EXCLUDE_EXTS"
    --no-import-volcano
  )
  if [[ -n "$OMICS_DATABASE" ]]; then
    GCT_ARGS+=(--omics-database "$OMICS_DATABASE")
  fi
  if [[ -n "$ADDED_BY" ]]; then
    GCT_ARGS+=(--added-by "$ADDED_BY")
  fi
  if [[ "$DRY_RUN" -eq 1 ]]; then
    GCT_ARGS+=(--dry-run)
  fi
  if [[ "$FORCE" -eq 1 ]]; then
    GCT_ARGS+=(--force)
  fi

  run_cmd "$ISPEC_BIN" "${ENV_ARGS[@]}" db import-results \
    --project-id "$PROJECT_ID" \
    --results-dir "$RESULTS_GCT_DIR" \
    --prefix "$PREFIX_GCT" \
    "${GCT_ARGS[@]}"
else
  echo
  echo "Skipping GCT import (dir not found): ${RESULTS_GCT_DIR}" >&2
fi
"""

    content = textwrap.dedent(header) + "\n" + textwrap.dedent(body).lstrip("\n")
    if not content.endswith("\n"):
        content += "\n"

    if out_path is not None:
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(content, encoding="utf-8")
        try:
            os.chmod(out_path, 0o755)
        except OSError:
            pass

    return ScaffoldImportScriptResult(
        content=content,
        out_path=out_path,
        script_name=suggested_name,
        gct_dir=resolved_gct_dir,
    )

